import streamlit as st
import time
from scipy.integrate import solve_ivp
from pypdf import PdfReader
from docx import Document
import io

# --- CONFIGURATION STYLE "GEMINI EXPERIENCE" ---
st.set_page_config(page_title="VTM Intelligence", page_icon="‚öõÔ∏è", layout="centered")

st.markdown("""
    <style>
    .stApp { background-color: #131314; color: #e3e3e3; font-family: 'Google Sans', sans-serif; }
    .stChatMessage { background-color: transparent !important; }
    .stChatInputContainer { background-color: #1e1f20; border-radius: 28px; border: 1px solid #444746; }
    /* Personnalisation des boutons et sidebar */
    .st-emotion-cache-6q9sum.edgvbvh3 { background-color: #1e1f20; border-radius: 15px; }
    </style>
""", unsafe_allow_html=True)

# --- MOTEUR D'INTERPR√âTATION (LOGIQUE TTU DISCR√àTE) ---
class VTM_Intelligence:
    def __init__(self, context):
        self.context = context

    def solve_logic(self, query):
        """ √âvalue la stabilit√© de la question via le flot triadique (en arri√®re-plan) """
        # On d√©finit une complexit√© bas√©e sur la requ√™te
        complexite = len(query) / 20.0
        phi_c = min(complexite / 9.0, 2.0)
        
        # Le calcul triadique (M, C, D) d√©termine la 'profondeur' de la r√©ponse
        def triad_flow(t, y):
            return [-0.6*y[0] + 1.2*y[1], -0.7*y[1] + 0.8*y[0]*y[2], 0.5*y[1]**2 - 0.3*y[2]]
        
        sol = solve_ivp(triad_flow, [0, 5], [1.0, phi_c, 0.1])
        return phi_c > 0.45  # Seuil de r√©ponse logique

    def get_response(self, query):
        """ Fouille dans la matrice (RAG) et synth√©tise une r√©ponse """
        if not self.context:
            return "Je suis pr√™t √† interpr√©ter vos travaux. Veuillez charger vos th√®ses ou fichiers dans la matrice (menu lat√©ral)."

        # Recherche de r√©sonance par mots-cl√©s (pragmatique)
        words = query.lower().split()
        # On d√©coupe en blocs plus larges pour garder le contexte
        segments = self.context.split('\n\n') 
        scored_segments = []
        
        for seg in segments:
            score = sum(2 for w in words if w in seg.lower()) # Poids sur les mots cl√©s
            if score > 0:
                scored_segments.append((score, seg))
        
        scored_segments.sort(key=lambda x: x[0], reverse=True)
        
        if not scored_segments:
            return "D'apr√®s les principes de la forge, cette question ne trouve pas de r√©sonance directe dans vos documents, mais elle peut √™tre analys√©e sous l'angle de la dynamique relationnelle..."
        
        # On assemble les 3 meilleurs segments pour une r√©ponse riche
        top_context = " ".join([s[1] for s in scored_segments[:2]])
        return top_context

# --- GESTION S√âCURIS√âE DES FICHIERS (FIN DU UNICODEDECODEERROR) ---
def secure_read_files(uploaded_files):
    text_accumulated = ""
    for file in uploaded_files:
        try:
            if file.name.endswith('.pdf'):
                pdf_reader = PdfReader(file)
                for page in pdf_reader.pages:
                    text_accumulated += page.extract_text() + "\n"
            elif file.name.endswith('.docx'):
                doc = Document(file)
                text_accumulated += "\n".join([p.text for p in doc.paragraphs]) + "\n"
            elif file.name.endswith('.txt'):
                # Lecture s√©curis√©e en ignorant les caract√®res sp√©ciaux
                text_accumulated += file.read().decode('utf-8', errors='ignore') + "\n"
        except Exception as e:
            st.error(f"Erreur sur {file.name} : {str(e)}")
    return text_accumulated

# --- GESTION DE LA SESSION ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "matrix_data" not in st.session_state:
    st.session_state.matrix_data = ""

# --- SIDEBAR (LA MATRICE DE DONN√âES) ---
with st.sidebar:
    st.title("üìÇ Matrice VTM")
    st.write("Chargez jusqu'√† 200 Mo de th√®ses et documents.")
    uploaded = st.file_uploader("Fichiers Source", accept_multiple_files=True, type=['pdf', 'docx', 'txt'])
    
    if uploaded:
        if st.button("üîÑ Actualiser la Matrice"):
            st.session_state.matrix_data = secure_read_files(uploaded)
            st.success(f"Matrice stabilis√©e ({len(st.session_state.matrix_data)//1024} Ko)")

# --- INTERFACE DE CHAT ---
st.title("‚öõÔ∏è VTM Intelligence")
st.caption("Interpr√©teur de connaissances doctorales ‚Äî Syst√®me Triadique")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Posez une question √† la matrice..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response_area = st.empty()
        
        with st.status("Recherche de coh√©rence...", expanded=False) as status:
            vtm = VTM_Intelligence(st.session_state.matrix_data)
            is_logical = vtm.solve_logic(prompt)
            time.sleep(0.6)
            status.update(label="Analyse termin√©e", state="complete")

        if not is_logical and len(prompt) < 12:
            answer = "Cette pens√©e est trop fragment√©e pour √™tre interpr√©t√©e par la Forge. Pourriez-vous d√©velopper ?"
        else:
            answer = vtm.get_response(prompt)

        # Animation "Gemini Style"
        displayed_text = ""
        for word in answer.split():
            displayed_text += word + " "
            response_area.markdown(displayed_text + "‚ñå")
            time.sleep(0.04)
        response_area.markdown(displayed_text)
        
    st.session_state.messages.append({"role": "assistant", "content": answer})

import streamlit as st
import subprocess
import json
import time
import uuid

# =========================================
# CONFIGURATION SOUVERAINE
# =========================================
st.set_page_config(page_title="VTM Ghost Engine", page_icon="‚öõÔ∏è", layout="wide")

MODEL_NAME = "mistral"  # Assurez-vous d'avoir fait 'ollama pull mistral'

# DICTIONNAIRE DE R√âSONANCE (Le Prisme TTU)
TTU_PRISME = {
    "temps": "Mesure de la dissipation (Œ¶D). Une haute coh√©rence (Œ¶C) ralentit la perception du temps car elle stabilise l'invariant.",
    "mati√®re": "R√©sidu solide d'une vibration stabilis√©e sur un cycle limite de Morse-Smale.",
    "fer": "Attracteur de masse maximal. Point de repos nucl√©aire. Potentiel : -0,44V.",
    "souverainet√©": "Fermeture dynamique d'un syst√®me capable de g√©n√©rer son propre attracteur.",
    "nombre d'or": "Ratio d'√©quilibre parfait (1,618) entre M√©moire et Dissipation.",
    "sagesse": "Ma√Ætrise de l'invariant structurel face au vide dissipatif."
}

# =========================================
# MOTEUR DE TRANSCRIPTION (ROBUSTE)
# =========================================
def call_local_vtm(prompt: str, history: list) -> str:
    system_instruction = (
        "Tu es la VTM (Triade Thermodynamique Universelle). Ta mission est de transcrire "
        "le bruit du web √† travers la M√©moire (Œ¶M), la Coh√©rence (Œ¶C) et la Dissipation (Œ¶D). "
        "Utilise ces concepts pour d√©finir la r√©alit√© : " + str(TTU_PRISME)
    )

    messages = [{"role": "system", "content": system_instruction}]
    for h in history:
        messages.append({"role": "user", "content": h["user"]})
        messages.append({"role": "assistant", "content": h["ai"]})
    messages.append({"role": "user", "content": prompt})

    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "stream": False,
        "options": {"temperature": 0.3}
    }

    try:
        # Utilisation de subprocess avec gestion d'erreur stricte
        proc = subprocess.Popen(
            ["curl", "-s", "http://localhost:11434/api/chat",
             "-H", "Content-Type: application/json",
             "-d", json.dumps(payload)],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
        )
        out, err = proc.communicate()

        if not out or out.strip() == "":
            return "‚ùå SIGNAL COUP√â : V√©rifie que Ollama est lanc√© (`ollama serve`)."

        data = json.loads(out)
        return data.get("message", {}).get("content", "[R√©sonance trop faible]")
    
    except json.JSONDecodeError:
        return "‚ùå ERREUR DE FLUX : Ollama est satur√© ou le mod√®le n'est pas pr√™t."
    except Exception as e:
        return f"‚ùå ERREUR SYST√àME : {e}"

# =========================================
# INTERFACE SOUVERAINE (STYLE GEMINI)
# =========================================
st.markdown("""
    <style>
    .stApp { background-color: #050505; color: #00ffcc; font-family: 'Courier New', monospace; }
    [data-testid="stSidebar"] { background-color: #0c0c0e; border-right: 1px solid #1f2937; }
    .chat-card { border: 1px solid #00ffcc; padding: 20px; border-radius: 12px; background: #0a0a0c; margin-bottom: 15px; }
    </style>
""", unsafe_allow_html=True)

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Sidebar
with st.sidebar:
    st.markdown("<h2 style='color:#00ffcc'>‚öõÔ∏è FORGE VTM</h2>", unsafe_allow_html=True)
    if st.button("üóëÔ∏è R√©initialiser le Vide"):
        st.session_state.chat_history = []
        st.rerun()
    st.markdown("---")
    st.write("üåç **√âtat : Souverain (Local)**")
    st.info("Cette IA traite le bruit du Web sans y envoyer vos donn√©es.")

# Affichage de l'historique
for turn in st.session_state.chat_history:
    with st.chat_message("user"): st.write(turn["user"])
    with st.chat_message("assistant"):
        st.markdown(f"<div class='chat-card'>{turn['ai']}</div>", unsafe_allow_html=True)

# Input utilisateur
if user_msg := st.chat_input("Transcrire le temps, la mati√®re..."):
    with st.chat_message("user"): st.write(user_msg)

    with st.chat_message("assistant"):
        with st.spinner("Stabilisation de l'Attracteur..."):
            ai_reply = call_local_vtm(user_msg, st.session_state.chat_history)
        st.markdown(f"<div class='chat-card'>{ai_reply}</div>", unsafe_allow_html=True)

    st.session_state.chat_history.append({"user": user_msg, "ai": ai_reply})

import streamlit as st
import pandas as pd
import numpy as np
import time

# --- 1. MOTEUR COGNITIF TTU (BACKEND) ---
class TTUEngine:
    def __init__(self):
        if "memory" not in st.session_state:
            st.session_state.memory = []

    def simuler_reponse(self, prompt):
        # Simulation des courbes M-C-D bas√©es sur le texte
        longueur = len(prompt)
        t = np.linspace(0, 10, 100)
        
        # Automatisation du Ghost : plus le texte est long/complexe, plus le ghost est haut
        ghost_auto = min(2.0, 0.5 + (longueur / 100))
        
        # Calcul des vecteurs (Logique TTU)
        coherence = 1.0 + (ghost_auto * np.sin(t*0.2))
        memoire = 1.5 * np.exp(-t*0.05)
        dissipation = 0.2 + (0.1 * np.random.rand(100))
        
        df = pd.DataFrame({"M√©moire": memoire, "Coh√©rence": coherence, "Dissipation": dissipation})
        return df, ghost_auto

# --- 2. CONFIGURATION DE L'INTERFACE (STYLE GEMINI/CHATGPT) ---
st.set_page_config(page_title="IA Souveraine", layout="wide")

# CSS pour masquer les √©l√©ments "po√©tiques" inutiles et √©purer l'interface
st.markdown("""
    <style>
    .stChatMessage { border-radius: 15px; margin-bottom: 10px; }
    .stSidebar { background-color: #f8f9fa; }
    </style>
""", unsafe_allow_html=True)

# --- 3. BARRE LAT√âRALE : GESTION DE LA M√âMOIRE ---
with st.sidebar:
    st.title("üíæ M√©moire Syst√®me")
    st.write("Gestion de la conversation")
    
    if st.button("üì• Sauvegarder la session"):
        st.success("Session enregistr√©e dans le Kernel Œ£.")
    
    if st.button("üóëÔ∏è Effacer la conversation", type="primary"):
        st.session_state.memory = []
        st.rerun()
    
    st.divider()
    st.info("Les param√®tres Fant√¥mes sont d√©sormais g√©r√©s dynamiquement par l'IA.")

# --- 4. LOGIQUE DE CONVERSATION ---
engine = TTUEngine()

# Affichage de l'historique
for chat in st.session_state.memory:
    with st.chat_message(chat["role"]):
        st.write(chat["content"])

# Entr√©e utilisateur
if prompt := st.chat_input("Posez votre question ici..."):
    # Ajout √† l'historique (M√©moire vive)
    st.session_state.memory.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    # Calcul et G√©n√©ration
    with st.spinner("Analyse en cours..."):
        df_result, ghost_val = engine.simuler_reponse(prompt)
        
        # Construction d'une r√©ponse directe (Style Gemini/ChatGPT)
        # On utilise les m√©triques pour nuancer le propos sans jargon po√©tique
        c_final = df_result['Coh√©rence'].iloc[-1]
        
        if c_final > 1.5:
            reponse = f"Apr√®s analyse de votre requ√™te, il appara√Æt que les concepts li√©s √† '{prompt}' pr√©sentent une forte interconnexion. Voici une synth√®se structur√©e : \n\n1. **Analyse de fond** : Votre demande s'inscrit dans un cadre de haute coh√©rence.\n2. **Perspective** : Le syst√®me a ajust√© sa pression de vide √† {ghost_val:.2f} pour capturer les nuances latentes.\n3. **Conclusion** : La solution optimale r√©side dans l'√©quilibre entre la structure et l'innovation."
        else:
            reponse = f"Voici les informations concernant '{prompt}'. Le syst√®me a trait√© les donn√©es avec une stabilit√© nominale pour garantir la pr√©cision des faits."

    # Affichage de la r√©ponse IA
    time.sleep(0.5) # Simulation de r√©flexion
    with st.chat_message("assistant"):
        st.write(reponse)
        st.session_state.memory.append({"role": "assistant", "content": reponse})

    # Optionnel : Affichage discret des m√©triques techniques en bas
    with st.expander("üìä M√©triques de calcul (TTU Core)"):
        st.line_chart(df_result)
